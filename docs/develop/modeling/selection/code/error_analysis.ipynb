{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de errores en conjunto de validación\n",
    "============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "El análisis de errores es el proceso para identificar, observar y diagnosticar predicciones erróneas de un modelo de aprendizaje automático, ayudandonos a comprender las áreas con fortalezas o debilidades de un modelo. Cuando decimos que \"la precisión del modelo es del 90%\", puede que no sea uniforme en todos los subgrupos de datos o puede haber algunas condiciones en los datos de entrada en las que el modelo falla más. Por lo tanto, es importante someter las métricas a una revisión más profunda para poder mejorarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando el análisis de errores en el problema censo de la UCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota: Este ejemplo fué adaptado de https://github.com/microsoft/responsible-ai-widgets/blob/main/notebooks/erroranalysis-interpretability-dashboard-census.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación\n",
    "\n",
    "Utilizaremos las librerías `interpret-community`, `raiwidgets`. La instalación de estos paquetes requiere de el compilador g++. Si no lo tiene instalado, puede hacerlo desde:\n",
    "\n",
    "```\n",
    "apt install g++\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitaremos instalar las librerias `interpret-community`, `raiwidgets` y `lightgbm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/santiagxf/E72102/master/docs/develop/modeling/selection/code/error_analysis.txt \\\n",
    "    --quiet --no-clobber\n",
    "!pip install -r error_analysis.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre el conjunto de datos del censo UCI\n",
    "\n",
    "El conjunto de datos del censo de la UCI es un conjunto de datos en el que cada registro representa a una persona. Cada registro contiene 14 columnas que describen a una una sola persona, de la base de datos del censo de Estados Unidos de 1994. Esto incluye información como la edad, el estado civil y el nivel educativo. La tarea es determinar si una persona tiene un ingreso alto (definido como ganar más de $50 mil al año). Esta tarea, dado el tipo de datos que utiliza, se usa a menudo en el estudio de equidad, en parte debido a los atributos comprensibles del conjunto de datos, incluidos algunos que contienen tipos sensibles como la edad y el género, y en parte también porque comprende una tarea claramente del mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://santiagxf.blob.core.windows.net/public/datasets/uci_census.zip \\\n",
    "    --quiet --no-clobber\n",
    "!mkdir -p datasets\n",
    "!unzip -qq uci_census.zip -d datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo importamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('datasets/uci_census/data/adult-train.csv')\n",
    "test = pd.read_csv('datasets/uci_census/data/adult-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generaremos 3 conjuntos de datos: entrenamiento, validación y testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "validation = test\n",
    "test, _ = train_test_split(test, test_size=0.9, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando un modelo para explorar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando nuestros conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['income'], axis=1)\n",
    "y_train = train['income'].to_numpy()\n",
    "X_test = train.drop(['income'], axis=1)\n",
    "y_test = train['income'].to_numpy()\n",
    "X_val = validation.drop(['income'], axis=1)\n",
    "y_val = validation['income'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train['income'].unique().tolist()\n",
    "features = X_train.columns.values.tolist()\n",
    "categorical_features = X_train.dtypes[X_train.dtypes == 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos un pequeño preprocesamiento antes de entrenar el modelo:\n",
    "\n",
    "- Imputaremos los valores faltantes de las caracteristicas numéricas con la media\n",
    "- Imputaremos los valores faltantes de las caracteristicas categóricas con el valor `?`\n",
    "- Escalaremos los valores numericos utilizando un `StandardScaler`\n",
    "- Codificaremos las variables categóricas utilizando `OneHotEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "def prepare(X: pd.DataFrame) -> Tuple[np.ndarray, sklearn.compose.ColumnTransformer]:\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    \n",
    "    num_pipe = Pipeline([\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    \n",
    "    transformations = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "    X = transformations.fit_transform(X)\n",
    "    \n",
    "    return X, transformations\n",
    "\n",
    "\n",
    "X_train_transformed, transformations = prepare(X_train)\n",
    "X_test_transformed = transformations.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos un modelo basado en `lightgbm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf = LGBMClassifier(n_estimators=1)\n",
    "model = clf.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuramos un objeto para general las explicaciones del modelo basado en el conjunto de datos en el que se entreno:\n",
    "\n",
    "> **IMPORTANTE:** Note que esta ténica require la creación de un modelo que sea interpretable. Es decir, en lugar de realizar el análisis en el modelo original (el cual podría tener una complejidad arbitraria), el análsis se hace sobre un modelo que pueda ser facilmente interpretable. Para generar este segundo modelo, se utiliza la técnica de Global Model Surrogate la cual consiste en entrenar un modelo **alumno** que trata de **imitar** al modelo **profesor**. Esta técnica claramente no es exacta y no tenemos ninguna garantía de que los errores que comete el modelo **alumno** son los mismos que los que comete el alumno **profesor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n"
     ]
    }
   ],
   "source": [
    "from interpret_community.common.constants import ShapValuesOutput, ModelTask\n",
    "from interpret.ext.blackbox import MimicExplainer\n",
    "from interpret.ext.glassbox import LGBMExplainableModel\n",
    "\n",
    "\n",
    "explainer = MimicExplainer(model=model,\n",
    "                           initialization_examples=X_train,\n",
    "                           explainable_model=LGBMExplainableModel,\n",
    "                           augment_data=True, \n",
    "                           max_num_of_augmentations=10,\n",
    "                           features=features, \n",
    "                           classes=classes, \n",
    "                           model_task=ModelTask.Classification,\n",
    "                           transformations=transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las explicaciones del modelo en nuestro conjunto de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n"
     ]
    }
   ],
   "source": [
    "global_explanation = explainer.explain_global(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar el análisis de errores, deberemos constuir un pipeline donde tengamos el preprocesamiento y el modelo propiamente dicho en un mismo objeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[('preprocessing', transformations),\n",
    "                                 ('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrimos la herramienta de análisis de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raiwidgets import ErrorAnalysisDashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "Removing duplicate bin edges for quantile binning of feature education-num. There are too many duplicate values for the specified number of bins.\n"
     ]
    }
   ],
   "source": [
    "ErrorAnalysisDashboard(global_explanation, model_pipeline, \n",
    "                       dataset=X_val,\n",
    "                       true_y_dataset=y_val,\n",
    "                       true_y=y_test, \n",
    "                       categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ejecutado el comando anterior, debería poder ver la herramienta de exloración de errores:\n",
    "\n",
    "<img src=\"../../../_images/ea_treemap.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación\n",
    "\n",
    "Podemos utilizar este gráfico para explorar la forma en que el modelo comente los errores. Para encontrar patrones, podemos ocmenzar buscando aquellos nodos en el arbol que tienen un color rojo más fuerte, lo que indica que esa combinación de atributos tiene un error alto al clasificarlos. El nivel de llenado del nodo indica que tan representativa es esa combinación de atributos en el conjunto de datos completo\n",
    "\n",
    "Esto quiere decir que si nos focalizamos en aquellos nodos con color más oscuro y nivel más alto, estamos atacando aquellas áreas donde tenemos más chances de mejorar la performance del modelo. Por ejemplo, en la imagen anterior vemos que cuando la relación es `Husband` o `Wife` y la cantidad de años de educación es mayor a 11.5 pero el capital es menor a $ 5035.50, estas instancias tienen una taza de error del 65% y representan el 35% de todos los errores que comete el modelo.\n",
    "\n",
    "Deberiamos investigar porque nuestro modelo no puede mapear a este tipo de instancias correctamente. Quizás haya un probema en la calidad de datos, una mala recolección, o quizás las características no fueron preprocesadas correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instancias con dificultades\n",
    "\n",
    "Una característica interesante de esta libreria es la capacidad de generar mapas de calor con aquellas combinaciones de atributos donde nuestro modelo tiene problemas. Esto nos permite ver rapidamente donde el modelo tiene inconvenientes en predecir correctamente y desde allí, analizár si el modelo es aceptable cometiendo estos errores o no:\n",
    "\n",
    "<img src=\"../../../_images/ea_heatmap.png\" width=\"600\" />\n",
    "\n",
    "En el ejemplo más arriba estamos comparando los predictores `relationship` y `education-num`. Como vemos, el modelo tiene grandes problemas con aquellas personas de más de 14 años de educación y que son mujeres casadas. Solo 1 persona fué clasificada correctamente representando una taza de error del 94%."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bea38c2984299ac640e8421861d34b2e05ee614f6236d2975c05eeb77366835f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
